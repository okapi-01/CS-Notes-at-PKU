# AI引论



---

## lecture 2. 数学基础

### 一些概念

样本空间：$\Omega = \{ \omega \mid \omega 为样本点\}$

对立事件：A与非A。 $\bar{A} \cup A = \Omega,\quad \bar{A} \cap A = \varnothing$

互斥事件：$A \cap B = \varnothing$

古典概型：有限性，等可能性。

条件概率：P(A|B)，B已发生时A的概率。**将 P(A ∩ B) 记作 P(AB)*
$$
P(A|B)=\frac{P(A B)}{P(B)}\\ \\
即\quad \begin{aligned} P(AB) &=P(A)\times P(B|A)\\ &= P(B) \times P(A|B) \end{aligned} \\
\\
可推广至 \quad \begin{aligned} P(ABC) &= P(AB) \times P(C|AB) \\&= P(A)\times P(B|A) \times P(C|AB)\end{aligned}
$$
独立：$P(AB) = P(A) \times P(B)$

两两独立：$P(AB) = P(A) \times P(B), P(BC) = P(B) \times P(C), P(AC) = P(A) \times P(C)$

相互独立：$P(ABC) = P(A) \times P(B) \times P(C)$

> [!NOTE]
>
> 两两独立包含于相互独立。
>
> eg. A：第一次骰为奇。 B：第二次骰为奇。C：两次和为奇。



### 全概率公式（由因求果）

$P(A) = \sum_{i=1}^{n} P(B_i) P(A \mid B_i)$

<img src="./../typora-images\image-20250302143433898.png" alt="image-20250302143433898" style="zoom:30%;" align="left"/>



### 贝叶斯公式（执果求因）

$$
P(B \mid A) = \frac{P(A B)}{P(A)}  = \frac{P(A \mid B) P(B)}{P(A \mid B) P(B) + P(A \mid \bar{B}) P(\bar{B})}
$$

即
$$
P(B_i \mid A) = \frac{P(B_i) P(A \mid B_i)}{\sum_{j=1}^{n} P(B_j) P(A \mid B_j)}
$$


### 随机变量

#### 离散

分布律（概率函数）：$P(X=x_k)=p_k$

分布函数：$F(x) = P\{X \leq x\} = \sum_{x_i \leq x} P\{X = x_i\} = \sum_{x_i \leq x} p_i$

#### 连续

分布函数：$F(x) = \int_{-\infty}^{x} f(t) \,dt$

概率密度：$f(t)$，满足$1 = \int_{-\infty}^{+\infty} f(t) \,dt$



### 数学期望

$E(X) = \int_{-\infty}^{+\infty} x f(x) \,dx$ （要求收敛）



### 方差和标准差

方差定义：$D(X) = Var(X) = E\{[X - E(X)]^2\}$

标准差：$\sigma(X) = \sqrt{D(X)}$

方差计算式：

(1) $D(X) = \sum_{k} [x_k - E(X)]^2 p_k$ （离散）

(2) $D(X) = \int_{-\infty}^{+\infty} [x - E(x)]^2 \cdot f(x) \,dx$ （连续）

(3) $D(X) = E(X^2) - [E(X)]^2$



---

## lecture 5. 搜索：UCS和A*

### 一致代价搜索 (UCS)

不断扩张代价轮廓 g(n)（BFS with 代价）

`完备性：如果存在解法则一定能找到` `最优性：找到的一定是最优解`

局限：没有考虑关于目标的信息。

<img src="./../typora-images\image-20250303132659916.png" alt="image-20250303132659916" style="zoom:40%;" align="left"/>



### 启发搜索 (Heuristic)

#### 启发函数h(x)

估计当前状态离目标状态还有多远。eg. 曼哈顿距离 (迷宫里哪怕没墙也要走横+竖的距离)



### 贪心

永远扩展看起来最近的 (可以看到h(x):每个点到终点的估计距离)

缺陷：没考虑代价；启发估计不一定准确。

<img src="./../typora-images\image-20250303135024165.png" alt="image-20250303135024165" style="zoom:33%;" align="left" />



### A*

$f(n) = g(n) + h(n)$

根据真实代价和未来估算代价的和来决定顺序，在终点被从列表中取出时结束搜索。

--> 是否保证最优？并不。如果出现悲观启发，就可能错过最优解。

<img src="./../typora-images\image-20250303142010762.png" alt="image-20250303142010762" style="zoom:33%;" align="left" />

#### 可接受启发

一个启发h是可接受的（乐观的），需满足$0\leq h(n)\leq h^*(n)$，$h^*(n)$是到目标的真实代价。

may delay, never miss.

`可证明最优解的前序节点(including self)一定比次优解先离开队列，所以一定最优`

：平衡启发估计的精确性所带来的计算量和广搜的计算量。

#### 一致启发

希望：删除重复访问。但A*中不允许重复访问则不一定得到最优解。

引入**一致性**：每条边的启发值 <= 实际动作代价 `不仅到终点的启发可接受，到其他点的启发也可接受`
$$
h(A) - h(B) < cost(A \ to \ B)
$$
则$f(n)$在同一条路径上不会减少。

--> 可以使A*在图搜上(每个节点只扩展一次)也是最优的。(可接受启发在树搜上最优)



---

## lecture 6. 搜索：逻辑和CSP

### 约束满足问题

#### 定义

- 状态 一些变量的赋值
- 目标 满足约束的状态
- 动作 给变量赋值
  - eg. 地图着色
    - 变量：各个块
    - 域：{红绿蓝}
    - 约束：相邻颜色不同（一元约束、二元约束、多元约束）
    - 目标：找到一种赋值

#### 分类

1. 离散变量
   * 有限域（地图着色）
   * 无穷域（几点做作业）
2. 连续变量

#### 解决方式

##### 1. BFS，DFS

##### 2. 回溯搜索（DFS加强版）

每次只考虑一个未赋值的变量，每一步都判断是否满足约束。

`但还是太慢辣。考虑搜索顺序和筛选。`

###### 改进1：最小剩余值启发（选择还有最少可能的变量）

<img src="./../typora-images\image-20250306181413971.png" alt="image-20250306181413971" style="zoom: 33%;" />

###### 改进2：选给剩下的变量留下最多可能的值

<img src="./../typora-images\image-20250306181510896.png" alt="image-20250306181510896" style="zoom:33%;" />

###### 改进3：提前筛选（去掉矛盾的值）

<img src="./../typora-images\image-20250306181606390.png" alt="image-20250306181606390" style="zoom:33%;" />

###### 改进4：约束传递

一条边的一致性：从X到Y是一致的，指对每一个剩余的X值，Y都有方法满足约束。

当X失去一个可能的值时，需要再一次检查邻居。

<img src="./../typora-images\image-20250306181645055.png" alt="image-20250306181645055" style="zoom:33%;" />



`CSP问题可以转化为SAT问题`

### SAT问题

是否存在一种布尔赋值组合，使所有的逻辑约束都能被满足。（域={0, 1}）

**字符**：x, 非x

**语句**：x||y

<img src="./../typora-images\image-20250306181719976.png" alt="image-20250306181719976" style="zoom:25%;" />

**DNF与CNF**: 析取范式与合取范式

<img src="./../typora-images\image-20250306181811396.png" alt="image-20250306181811396" style="zoom:33%;" />

#### 算法

##### 1. DPLL算法(Davis-Putnam-Logemann-Loveland)

把约束写成CNF形式，每个子句只有四种可能：

(1) 已经满足 (2)无法满足 (3) 单字符`只剩一个字符还没赋值,其他都为假` (4)其他

所以：

- 单字符传递：单字符情况时将之赋值为真。

- 布尔约束传递：重复使用单字符传递，直到无法用为止。

##### 2. 矛盾指引的子句学习算法（CDCL算法）

**隐含图**：逻辑推导图

**一分为二**：划分片区，推出新约束

<img src="./../typora-images\image-20250306182129608.png" alt="image-20250306182129608" style="zoom:30%;" />

*最好划在最贴近上面，比如得出不能同时 not x1 和 not x5，这样可以快速促发单字符传递 (由1推5, 因为1在前一层，5在后一层)* ---> 每次只学到一个条件



---

## Lecture7. 对抗搜索

**博弈**

1. 零和博弈

2. 一般博弈：智能体获得的效用是独立的，可能合作、无关、竞争。

**零和博弈**

状态的价值：从该状态出发可能获得的最大最终效用

### 极大极小搜索：

<img src="./../typora-images\image-20250310140443850.png" alt="image-20250310140443850" style="zoom:33%;" />

**Alpha-Beta剪枝**：

这两个就不用考虑了

<img src="./../typora-images\image-20250310142316682.png" alt="image-20250310142316682" style="zoom:33%;" />

但对手不一定绝对理性，所以不用完全按最悲观走法走，而采用期望效用作为父节点效用。（此时就没法剪枝了）



***问题：搜索深度加大时资源耗费过多，使用效用函数作未来估计则不保证最优。**



---

## Lecture 8. 蒙特卡洛搜索

用大规模随机抽样来近似问题的解

`蒙特卡洛算圆周率：落在圆内的点 / 落在正方形内圆外的点 = pi / 4`

抽样越多越精确，准确度与样本方差相关



#### 1. ε-greedy

1-ε 选当前最优，ε 随机选一个剩下的。

#### 2. Upper Confidence Bound

如何平衡不确定性：试图平衡估值的大小和探索次数的多少
$$
A_{t+1} = argmax_a \left[ Q_t(a) + c \sqrt{\frac{\ln t}{N_t(a)}} \right]
\\Q_t表示现在的估值，N_t表示尝试a的次数，t表示总尝试次数
\\c:超参数，用于平衡估值和信任度对决策的影响
$$
这样，会保证每个都得到一定的探索，并在得到一定的探索后专注于最大者

#### 3. 从UCB到博弈（MCTS）

每一次选择都是一次多臂老虎机。训练过程：选择(`每一步都是老虎机`) -> 扩展(`若之前没考虑过这里怎么走，则扩张一个点`) -> 模拟(`随机走到头,或者一个默认算法`) -> 回溯

<img src="./../typora-images\image-20250317142425791.png" alt="image-20250317142425791" style="zoom:33%;" />



---

## Lecture 9. 机器学习基础与回归

### 机器学习模型

1. **判别式模型**：“这个人是不是我”，“我这学期每周学习30小时，绩点会是多少”

   given input x, predict label y --> learn p(y|x)

   *<u>监督式学习</u>（需要label）

2. **描述式模型**：

   given input x, learn p(x)

   *<u>非监督式学习</u>

3. **生成式模型**:

   given a latent vector z, generate x from z --> learn p(x|z)

   *<u>非监督式学习</u>

<u>弱监督式学习</u>：并非每个都有标签 / 标签力度不一样 / 有错误的标签

<u>自监督式学习</u>：有先验知识 (eg. 所有鸟都有喙)

<u>强化学习</u>：数据本身需要自己获得。

### 一、判别式模型

判别式模型是一个包含参数的函数，通过调整模型参数来 **拟合** (fit) 训练数据。

- 回归：标签是连续的（eg. 预测房子的房价）
- 分类：标签是离散的（eg.狗的品种）

模型评估：训练误差、测试误差。（**泛化**：generalization能力。**过拟合**：overfitting, 训练误差 < 测试误差。**欠拟合**：训练误差仍然很大，可能模型不够好 / 训练不够）

<img src="./../typora-images\image-20250320162525668.png" alt="image-20250320162525668" style="zoom:50%;" />



#### 1. k 近邻算法 (k-Nearest Neighbor, k-NN)

return 训练样本中离测试样本最近的 k 个样本中占多数的那个标签

优点：只需要一个距离函数即可，不需要训练。

缺点：需要存储所有样本；需要计算测试样本到所有训练样本的距离；距离函数不好找；不适合高维空间。

**维度灾难**：距离在高维空间失去意义，几乎所有点都有相同距离。

<img src="./../typora-images\image-20250320163544470.png" alt="image-20250320163544470" style="zoom:30%;" />

k-NN 是<u>非参数化模型</u>，模型不能被有限参数定义，或不包含参数。需要保留训练样本。

<u>参数化模型</u> 包含可训练的参数，通过拟合训练数据来估算模型参数，可以写成 𝑦 ≈ 𝑓(x) , 𝑓为包含参数的模型



#### 2. 线性模型*——最简单的参数化模型*

$$
f(x)=w^Tx+b
$$
线性模型做回归任务就叫**线性回归**

线性模型做分类任务就叫**逻辑回归**

<img src="./../typora-images\image-20250320164531826.png" alt="image-20250320164531826" style="zoom:33%;" />

##### (1) 线性回归

如何训练？通过**最小化损失函数**

- 平方损失函数 (最小二乘法) $L(f(x_i),y_i) = (f(x_i)-y_i)^2$ `对于线性回归问题很常用`

  可以通过**梯度下降**解决此优化问题。
  $$
  \min_{w,b} \frac{1}{n} \sum_{i \in [n]} L(f(x_i), y_i)
  \\可以写成J(w, b) = \frac{1}{n} \sum_{i \in [n]} L(f(x_i), y_i)
  \\随机选定w, b的初始值，逐步调整 w, b以降低 J(w, b) 。
  \\每次沿着使 J(w, b) 变小最快的方向使 w, b 走一小步：
  \\w \leftarrow w - \alpha \cdot \frac{\partial J(w, b)}{\partial w}, \quad b \leftarrow b - \alpha \cdot \frac{\partial J(w, b)}{\partial b}
  \\α：学习率（一个超参数）
  $$

​		线性回归的梯度下降：

​		<img src="./../typora-images\image-20250320170044653.png" alt="image-20250320170044653" style="zoom:40%;" />

​		问题：会得到局部最小值，所以刚开始值的选择会影响很大。

​		对于凸函数，局部最优解一定是全局最优解。

​		这是一种 **经验风险最小化框架 (Empirical Risk Minimization) ERM**，最小化训练过程中误差。

##### (2) 二分类问题（逻辑回归）

采用 sgn(f(x)) 来使结果只有 1 或 -1.

如何学习？

- 经验风险最小化框架

  如何规定损失函数？可以采用零一损失函数。答对了损失 0，答错了损失 1.

  但这个函数不连续不可微，无法学习。

  

- 最大似然框架

  `似然：likelihood。P(x|θ)`

  对观测数据进行(条件)概率建模，制定一些参数，然后学习这些参数。

  因为概率连乘容易爆精度，所以采用最大化对数似然，使整个数据集出现的概率最大。

  步骤：

  * 首先对 $p(y|x;\theta)$ 建模。

    已有 $f(x) = w^T x + b$

    采用 sigmoid 函数把 f(x) 转化为值域 [0, 1] 的函数
  
    <img src="./../typora-images\image-20250324144653619.png" alt="image-20250324144653619" style="zoom:33%;" />
    $$
    \sigma(x) = \frac{1}{1 + e^{-x}} \\有很好的性质：1 - \sigma(x) = \frac{e^{-x}}{1 + e^{-x}} = \frac{1}{1 + e^{x}} = \sigma(-x)
    $$
  
  * 写出每个数据的出现概率表达式，乘起来成为整个数据集的出现概率，取对数，找到 θ 使最大化。
  
    即求解：
    $$
    \max \sum_{i \in [n]} \log \left[ \sigma(y_i(w^T x_i + b)) \right] = \sum_{i \in [n]} \log \left[ \frac{1}{1+e^{-y_i(w^T x_i + b)}} \right]\\
    = - \sum_{i \in [n]} \log \left[ 1 + e^{-y_i(w^T x_i + b)} \right]\\
    $$
    也即最小化平均损失函数：
    $$
    \min_{w, b} \frac{1}{n} \sum_{i \in [n]} \log \left[ 1 + e^{-y_i(w^T x_i + b)} \right]\\
    $$
    其中，$\log \left[ 1 + e^{-y_i(w^T x_i + b)} \right]即-\log (p_i)$被称为交叉熵，连续可微且凸，易优化。
  
    在 {1, 0} 定义下，更常被写为 $p(y|x) = -\frac{1}{n} \sum_{i=1}^n \left[ y_i \log(p_i) + (1-y_i) \log(1-p_i) \right]$
  
    (因为无法写成 $\sigma(y_i(w^T x_i + b))$ 后转写为 $\sigma(w^T x + b)^y \cdot \left(1 - \sigma(w^T x + b)\right)^{1-y}$, 具体推导过程：)
    $$
    似然函数：L(w, b) = \prod_{i=1}^n \sigma(w^T x_i + b)^{y_i} \left(1 - \sigma(w^T x_i + b)\right)^{1-y_i}\\
    \log L(w, b) = \sum_{i=1}^n \left[ y_i \log \sigma(w^T x_i + b) + (1-y_i) \log \left(1 - \sigma(w^T x_i + b)\right) \right]\\
    因为\ p_i = \sigma(w^T x_i + b)，所以可简化为\sum_{i=1}^n \left[ y_i \log(p_i) + (1-y_i) \log(1-p_i) \right]
    $$
    
    > [!NOTE]
    >
    > 交叉熵是一种替代损失函数。
    >
    > 除此之外，合页函数 (Hinge Loss) 也是常用的替代损失函数，$L(f(x_i),y_i) = max(0, 1 − 𝑦_𝑖 𝑓(𝑥_𝑖))$
    >
    > <img src="./../typora-images\image-20250403095808283.png" alt="image-20250403095808283" style="zoom:33%;" />
    
    
    
  
- 还有最大后验框架...等

  先验：P(θ)  似然：P(x|θ)  后验：P(θ|x)

  

- 逻辑回归总结

  <img src="./../typora-images\image-20250403100702827.png" alt="image-20250403100702827" style="zoom:25%;" />
  
  

##### (3) 多分类问题

- 可以训练 k 个二分类器。

  缺点：训练代价大；互相独立，没法统一（对一个分类器乘以一万并不影响其判断，却会影响argmax）

- Softmax 回归

  `本质上是取max，但直接取就不可微，所以采取软化max算法`

  训练 k 个模型，取第 k 类的概率是 $f_k(x)$

  不能使用 sigmoid 函数，因为需要满足各类概率加起来等于一。

  所以使用 softmax 归一化概率：$p(y = k \mid x) = \frac{e^{f_k(x)}}{\sum_{j=1}^K e^{f_j(x)}}$

  采用指数放大效果，使得如果 $f_k(x)$ 显著高于其他，则其概率很接近一。
  
  优化方法：
  
  <img src="./../typora-images\image-20250403105109942.png" alt="image-20250403105109942" style="zoom:25%;" />
  
  > [!NOTE]
  >
  > 思考：二分类问题中，softmax 和 逻辑回归并不一致，如何统一？
  >
  > `deepseek：本质上是一致的，只是参数形式不同，softmax会有冗余参数，把两个参数缩为一个即和逻辑回归一致。`



### 二、用正则化解决过拟合问题

常见过拟合原因：几个特征维度权重过大，支配了预测；或对没用的特征维度赋予了一定的权重。

加入正则化项 $\lambda \cdot R(f)$ :
$$
\min_{f} \frac{1}{n} \sum_{i=1}^n L(f(x_i), y_i) + \lambda \cdot R(f)
$$

1. 权重过大

   惩罚少数过大的权重维度。

   采用 **L2 正则化** $R(f) = \|w\|_2^2 = w^T w = \sum_{j=1}^d w_j^2$

2. 没用的维度

   鼓励稀疏分布 (使大部分权重为零)。

   采用 **L1 正则化** $R(f) = \|w\|_1 = \sum_{j=1}^d |w_j|$

带正则化的回归：

1. 岭回归：线性回归 + L2 正则化

2. Lasso 回归：线性回归 + L1 正则化

   <img src="./../typora-images\image-20250403110622699.png" alt="image-20250403110622699" style="zoom:33%;" />
   $$
   可以直观理解，圆形使半径最小，菱形使更易收敛到尖点\\
   如果采用非线性回归（如神经网络），可能就不是一个圆，而是一个复杂图形，\\
   可能就不是一定是这个效果，但还是有这个趋势。
   $$

3. 逻辑回归 (完整形式)：交叉熵损失 + L2 正则化

4. 支持向量机 (SVM) ：合页损失 + L2 正则化



#### 超参数与模型选择

λ 是一个超参数，过小就会过拟合，过大就会欠拟合。学习率、选择哪个模型、如何下降都可视作超参数。

使用 **验证集 (validation set)** 来选择最优超参数。

- 在训练集、测试集之外引入验证集，通常按照 80%，10%，10% 比例划分。
- 用不同的超参数在训练集上训练完后，在验证集上验证模型误差，选择验证集上误差最小的超参数组合。
- 使用选定的模型和超参数在测试集上最终测试模型误差，估计模型泛化能力。

**k-折交叉验证 (K-fold Cross-Validation)**:

- 将测试集外的所有数据随机分为 k 份
- 对一组给定的超参数组合，每次使用 K-1 份数据训练模型，用1份验证模型误差，将 K 次验证的模型误差取平均来衡量该组超参数的好坏。
- 遍历所有可能的超参数组合，返回平均误差最低的超参数组合。
- 在测试集上最终测试模型性能。



---

## Lecture 11. 决策树与随机森林

线性分类不一定搞得定，所以需要非线性分类器。

### 一、决策树

​	（划若干条线）

<img src="./../typora-images\image-20250331144012925.png" alt="image-20250331144012925" style="zoom:33%;" />

一棵好的决策树：将样本不断划分为纯度更高的集合。

#### 1. 纯度与划分

- 信息熵：
  $$
  E[-log(p(x))] = -\sum_x p(x) \times log(p(x))
  $$
  熵一定非负，当且仅当 p(x) 为一个确定分布 `(一个事件概率为1, 其余为0)` 时，H(x) = 0.

  * 琴生不等式：对于凸函数，$f\left(\sum_{i=1}^n \lambda_i x_i\right) \leq \sum_{i=1}^n \lambda_i f(x_i) ，其中  \lambda_i \geq 0  且 \sum_{i=1}^n \lambda_i = 1$ 
  * 由琴生不等式得到，所有事件等概率时，熵最大。

- **划分准则(1)：信息增益**

  信息增益 = 分类前纯度 - 分类后各类纯度加权和

  选择信息增益最大的属性进行划分。

  但只考虑信息增益最大的话，会倾向于选择分类最多的特征（比如九个科学家平均分为九类，则熵一定最小 (为 0) ）。

- **划分准则(2): 增益率**

  增益率 = 增益 / 属性自己的信息熵

  `属性熵指的是4/9人认真工作5/9人不认真工作的熵。或者1/9人序号为i的熵。分类得到的信息熵则是分成4/9 5/9后两类里是否是好科学家的熵。`

- **划分准则(3)：基尼指数**

  基尼指数：拿出两个，两个不是一类的概率。

  $\text{Gini}(D) = \sum_{k=1}^K \frac{|D_k|}{|D|} \left( 1 - \frac{|D_k|}{|D|} \right) = 1 - \sum_{k=1}^K \left( \frac{|D_k|}{|D|} \right)^2$

  对每个属性 A 的分类方法求 Gini（每一类单独 Gini 然后按照占比加权和）

  选取基尼指数最小的属性来分类。（也可以选择最小基尼指数率）

#### 2. 属性离散到连续

二分法：将连续的属性变为若干个离散的属性（也可以多分法：0-9 插入若干个阈值可以变为{0, 1, 2, 3}, {4, 5, 6, 7}, {8, 9}）。

- 对每个属性，计算阈值插在哪里可以获得最大增益
- 选择增益最大的属性进行划分。

#### 3. 标签离散到连续

给出科学家的水平打分？则分类问题变为回归问题，需要使用回归树。



### 二、回归树

离散问题中使用信息熵计算纯度，回归问题中直接采用方差即可（称为 L2 Loss）（不用除以数量）

<img src="./../typora-images\image-20250403183056557.png" alt="image-20250403183056557" style="zoom:33%;" />



### 三、随机森林

1. 构造若干个决策树。
2. 对每个决策树，对训练集进行随机采样得到一个独立的训练集（样本扰动）
3. 对每个决策树，只选择一部分属性进行子树划分训练（属性扰动）
4. 最后，用所有训练好的决策树的平均预测（如多数类）作为对测试样本的输出



---

## Lecture 12. 神经网络与反向传播

### 一、MLP 多层感知器 (Multi-Layer Perceptron)

<img src="./../typora-images\image-20250403162604994.png" alt="image-20250403162604994" style="zoom:33%;" />

也叫全连接神经网络。隐层维度和层数都可自定义。

传到下一层的值 = $f(w^TX + B)$, f 为激活函数

#### 激活函数

<img src="./../typora-images\image-20250403163049013.png" alt="image-20250403163049013" style="zoom:25%;" />

Sigmoid 和 tanh 都和真实神经信号类似，但实际上只要是一个非线性函数就能力差不多。（训练难度不同）（ReLU是很好的默认选择！在大部分常见问题上表现良好！）

#### 反向传播

<img src="./../typora-images\image-20250407132403448.png" alt="image-20250407132403448" style="zoom:33%;" />

关心两个问题：1. 得到上游传播时，累加所有路径。2. 得到上游梯度后，向前传多少。（本地梯度在前向传播时就可以算好记下）

因为 sigmoid 可能发生梯度消失现象 (乘起来太小，导致梯度几乎为 0)
$$
\sigma(x) = \frac{1}{1 + e^{-x}} \\
\frac{d\sigma(x)}{dx} = \frac{e^{-x}}{(1 + e^{-x})^2}
= \left( \frac{1 + e^{-x} - 1}{1 + e^{-x}} \right) \left( \frac{1}{1 + e^{-x}} \right) = (1 - \sigma(x)) \cdot \sigma(x)
$$
所以 ReLU 更常用，不容易发生梯度消失现象。

#### 梯度下降

1. Full GD: 使用全部数据的误差函数更新梯度
2. 随机 GD: 使用一个数据的误差更新梯度
3. mini-batch GD: 每次抽取一批样本更新梯度



---

## Lecture 13. 计算机视觉

### 一、图像分类

#### 基于手工特征提取的图像分类算法

- 特征提取算子

  1. 梯度直方图（HOG 特征描述子）

     <img src="./../typora-images\image-20250414134529586.png" alt="image-20250414134529586" style="zoom:33%;" />

     投票：可以只看数量，也可以梯度大小累加。

     <img src="./../typora-images\image-20250414134609216.png" alt="image-20250414134609216" style="zoom:33%;" />

  

  2. Haar 特征

     擅长人脸识别。

     把 HOG 特征中的向量 filter 变成矩阵 filter。

     <img src="./../typora-images\image-20250414140809858.png" alt="image-20250414140809858" style="zoom:25%;" />

     

  3. SIFT 特征

  

- 分类器




#### 基于卷积神经网络的图像分类算法

- 卷积层：其实就是一个 filter

- 如果使用多个 filter，就会构成很厚的一个特征图

- 可以一步一步形成一个神经网络（也有激活层）

- 正则化算子：

  如果图片中有极端值，会导致训练不稳定，所以我们将他们正则化后再输入给下一层

  一般放在激活层前，可以映射到比较好的激活函数区间。

  - 批归一化：batch normalization

    减去平均值再除以方差，则输出 [0, 1] 的数据

    （一般归一化会经过相同处理的部分）

  - BN层：引入可学习的权重和偏移量（记录下来之前的平均值和方差）

  - 更多归一化方法：

    <img src="./../typora-images\image-20250414144513256.png" alt="image-20250414144513256" style="zoom:30%;" />

- 池化层：pooling

  降采样。

  比如把四个块变成一个块：

  最大池化：选最大的那个作为整个的代表

- dropout：

  训练的时候每次以 p 的概率忽视一些神经元，以此来防止过拟合。



### 二、图像数据增强

水平翻转、随机裁剪、旋转、亮度、饱和度、颜色...

对可能过拟合的部分都引入噪声。



---

## Lecture 14. 计算机视觉-三维重建

### 一、从三维到二维（forward）

- 针孔模型：小孔成像

  但小孔通光量较小，所以人眼和相机利用凸透镜进行光线调整，可以获得更多光。

  可以通过相似三角形进行成像计算。

- 摄像机几何：

  1. 世界坐标系转换为相机坐标系

  2. 小孔成像

  3. 成像平面转化为图像（加一个偏移 [cx, cy] 转到图像坐标系）

     <img src="./../typora-images\image-20250417155931844.png" alt="image-20250417155931844" style="zoom:33%;" />

     如何确定相机内外参：标定（Calibration，拍一些已经知道的图像）（OPENCV 提供标定法）



### 二、从二维到三维（inverse）

- 三维重建

  <img src="./../typora-images\image-20250417162352143.png" alt="image-20250417162352143" style="zoom:33%;" />

- 特征点检测和匹配

  可以：算出特征，作最近邻搜索。（SIFT 就效果较好）

  难点情况：有遮挡、纹理缺乏、光照变化

- 于是有了一系列各种各样的算法（没细讲，可以看 ppt）



---

## Lecture 15. 自然语言处理

1. 上下文无关的文法 Context-Free Grammar

   <img src="./../typora-images\image-20250417163840338.png" alt="image-20250417163840338" style="zoom:33%;" />

   <img src="./../typora-images\image-20250417163901910.png" alt="image-20250417163901910" style="zoom:33%;" />

   可以加入统计概率。

2. 句法分析：自顶向下找到其短语结构，但低效，所以需要自底向上的算法。

   - CYK 算法
   - 或者 A* 搜索，可以比 CYK 快。

3. n 元模型 (n-gram)：一次考察 n 个单词

   *就是 Context Length

4. 分词 (Tokenization)：将句子切割为词 / 将段落切割为句子。

5. 马尔可夫模型 (Markov Model)：

   *马尔可夫性：无后效性。在 t 之前的内容不参与接下来的判断。



---

## Lecture 16. 自然语言处理

### 一、朴素贝叶斯模型

<img src="./../typora-images\image-20250430164618208.png" alt="image-20250430164618208" style="zoom:33%;" />

#### 平滑

1. 加法平滑 （词汇类别：出现在数据库中的所有词）

   <img src="./../typora-images\image-20250421132206219.png" alt="image-20250421132206219" style="zoom:33%;" />

2. 拉普拉斯平滑：α = 1 时的加法平滑

   <img src="./../typora-images\image-20250421132230117.png" alt="image-20250421132230117" style="zoom:38%;" />



### 二、信息检索

1. 词频：$tf = \frac{n}{N} \quad \text{或} \quad tf = \log_{10}(n + 1)$

2. 逆文档频率 Inverse Document Frequency (idf)：$idf = \log_{10} \left( \frac{D}{1 + d} \right)$

   - $D$：语料库中包含的文档总数量  
   - $d$：语料库中出现某个词的文档数量

   于是可以通过 tf * idf 来弱化常见词，保留重要的主题词。

3. 词袋模型 Bag-of-Words Model (BoW): 就是构建词频向量

   缺点：字典大，向量稀疏；关键词重要性未体现。

此外，我们希望可以脱离文本单独获得词汇本身的信息。

4. 词表示：

   - 独热表示 (one-hot representation)：

     每个词有一个单独对应向量。

     <img src="./../typora-images\image-20250421135229965.png" alt="image-20250421135229965" style="zoom:25%;" />

     缺点：字典大，太稀疏；仅将词符号化，不包含任何语义信息，没有考虑词的相关性

   - 分布式表示 (distributed representation)：

     理论基础：上下文相近的词，其语义也相近。
     
     CBOW 模型
     
     <img src="./../typora-images\image-20250430165418374.png" alt="image-20250430165418374" style="zoom:33%;" />
     
     称为 embedding。



---

## Lecture 17. 自然语言处理-Transformer

一、seq2seq

二、attention





---

## Lecture 18. 知识图谱

### 一、概况

<实体，关系，实体>

问题：

- 知识难获取
  1. 隐性知识、过程知识等难以表达
  2. 领域知识的形式化表达较为困难
  3. 不同专家之间知识可能存在不一致性
  4. 知识表达难以完备，缺漏是常态
- 知识难应用
  1. 应用易于超出预先设定的知识边界
  2. 很多应用需要常识的支撑
  3. 难以处理异常情况
  4. 知识更新困难

应用场景：搜索，推荐系统，判案，医疗诊断...

### 二、构建与应用

关键步骤：知识抽取、知识表示、知识推理

#### 知识抽取

- 实体抽取：
  1. 基于规则：...认为，...提出，...坐落于...
  2. 机器学习
- 关系抽取
  1. 基于模板：省会、创造于...
  2. 机器学习
- 事件抽取：一次性获取一句话中多组关系

#### 知识表示

需求：方便计算机处理，人类友好。

##### ----一阶谓词逻辑

- 命题变元：“现在是上课时间”
- 个体常量：具象或特定的个体（北京大学）
- 个体变量：抽象或泛指的个体（北京大学某学院，当前时间）
- 个体域：个体变量的值域
- n 元谓词：North(PKU, China)，谓词是一个命题
- 函数：作用在实体上形成一个新的实体。Principal(PKU)
- 量词：全称量词(all)，存在量词(exist)。

优点：精确性，通用性，自然性，模块化。

缺点：管理困难，不能表示非确定性知识、过程性知识和启发式知识，效率低。

#### 知识推理

#### ----逻辑表示推理

- 自然演绎：正向推理

  <img src="./../typora-images\image-20250512144154670.png" alt="image-20250512144154670" style="zoom:30%;" />

- 归结演绎：反证法

  将谓词公式看作子句集，将结论的否定式写为子句加入子句集，推出矛盾。

- 产生式表示法：（产生式系统）拥有一套规则库，然后进行推理

- 框架表示法：构建struct

##### ----图神经网络（GNN）

- 目标：与节点标号无关。
- 核心思想：对每个点用等同的方式进行处理，通过聚合邻居节点的特征学习中心节点表示。
- 核心任务：设计不同的消息聚合方式

<img src="./../typora-images\image-20250515153108298.png" alt="image-20250515153108298" style="zoom:33%;" />



## Lecture 21. 机器人

- 效应器 (effector)
- 传感器 (sensor)：主动传感器，被动传感器

规划三级层次：任务规划、运动规划、运动控制

*策略：$\pi(a|S)$ `(其实就是一个P(action | State))`

### 一、定位与地图创建 (Localization and Mapping)

#### 蒙特卡洛定位

- 基于粒子滤波器 (particle filter)
- 已知全部地图信息

过程：

- 预测：按高斯分布取十个点，知道它们的 h
- 更新：衡量 f()，来给定一个概率函数。
- 重采样：用更新后的概率在原来的十个点中取十个点（则概率大的点有多个聚合，在往前一米的估计中会散开）



### 二、运动规划

- 工作空间：实际物理空间（机器人有体积）
- 构型空间 (configuration space)：C-space，机器人能拥有的所有状态的空间（机器人为一个点，障碍物膨胀来表示机器人到不了的区域）。

#### ----快速探索随机树 RRT

0. 导入地图，起始点，终点
1. 在地图上随机采样一点
2. 计算 RRT 树上离随机点最近的点
3. 以 Xnear 为起点，以 Xnear -> Xrand 射线为方向，前进 Stepsize 的距离
4. 检查是否碰撞障碍物，若碰撞则无效，若不碰撞则将 Xrand 加入 RRT 树
5. 检查是否离目标点足够近，若足够近，则从目标点沿树回溯即可得到运动路径。



### 三、运动控制

- 动力学模型 (dynamics model)：控制量如何算出结果。比如`F = ma` `如果机器人位于构形 Q 并具有速度 𝑞，施加扭矩 𝑢，就有加速度 = 𝑓(Q,𝑞,𝑢)`
- 逆动力学模型 (inverse dynamics): 实现想达到的状态需要如何改变控制量
- 控制律：无法精确控制，所以引入控制过程来避免误差累计。查看机器人自认为其所处的位置，并将其与
  它想要处于的位置进行比较，然后施加扭矩来最小化误差。PID！



---

## Lecture 22. 强化学习

强化学习通常解决一类特殊的决策问题，称为马尔科夫决策问题。

### 一、马尔可夫决策问题 (MDP)

- 未来的状态由当前状态和行动确定，和过去无关
- 决策目标和代价由奖励函数给出
- 不假定环境有确定和已知的转移模型

1. 策略（确定性策略$a = \pi(S)$，随机策略a~$ \pi(a|S)$）

2. 轨迹：状态、行动、奖励的序列 $\tau = (s_0, a_0, r_0, s_1, a_1, r_1, ..., s_t, r_t, ...)$

3. 累计收益：$G(\tau) = r_0 + \gamma r_1 + \gamma^2 r_2 + \cdots = \sum_{i = 0}^{T} \gamma^i r_i$

   折扣因子 γ 描述未来收益的重要程度。一般 > 0.9。

4. 状态价值：表示从s出发执行策略Π能获得的累计收益。$V_{\pi}(s) = E_{\tau\sim\pi}\left[\sum_{t} \gamma^{t} r_{t} \big| s_0 = s\right]$

5. 动作价值：（a可以不来自策略，执行之后的动作都来自策略）$Q_{\pi}(s, a) = E_{\tau\sim\pi}\left[\sum_{t} \gamma^{t} r_{t} \big| s_0 = s, a_0 = a\right]$

   $V_\pi(S) = \int_{\pi(a|s)}Q(s,a)$



### 二、贝尔曼方程

Bellman期望方程：
$$
\begin{align}
V_{\pi}(s) &= E_{\tau\sim\pi}[G(\tau)|s_0 = s] \\
&= E_{\tau\sim\pi}[r_0 + \gamma r_1 + \gamma^2 r_2 + \cdots|s_0 = s] \\
&= E_{(a_0,r_0,s_1,a_1,r_1,s_2\cdots)\sim\pi}[r_0 + \gamma(r_1 + \gamma r_2 + \cdots)] \\
&= E_{(a_0,r_0,s_1)\sim\pi}[r_0 + \gamma E_{(a_1,r_1,s_2\cdots)\sim\pi}[r_1 + \gamma r_2 + \cdots]] \\
&= E_{(a_0,r_0,s_1)\sim\pi}[r_0 + \gamma V_{\pi}(s_1)] \\
&= \sum_{a} \pi(a|s) \sum_{s',r} p(s'|s,a) [r + \gamma V_{\pi}(s')]
\end{align}
$$

Bellman最优方程：（即直接求max）

$\pi$取最优策略时，期望方程与最优方程一致。

- 策略估值：根据 bellman 方程一层层迭代计算（只要离散，就会迭代到最优解）
- 策略提升：策略为贪心选择动作
- 策略迭代：策略估值+策略提升。有限MDP一定会收敛到最优解。四个算完后取平均更新。
- 值迭代：四个算完后取最大值更新。



### 三、基于价值函数的学习方法

Q-learning：根据轨迹更新（off-policy，轨迹和学习的策略并不相关）

DQN：



---

## Lecture 23. 多智能体

- 静态博弈：同时行动
- 动态博弈：行动有先后
- 单步博弈
- 重复博弈
- 纯策略：确定性的选择一个动作
- 混合策略：各选项概率不为0或1
- 收益函数：每个参与者在每种行动组合下各自的效用

### 更好的策略？

- 占优策略：对于其他参与者的每个选择，我的策略 s 总是好于 s'，则 s 称为占优策略。

- 帕累托改善：不损害他人利益的情况下，我的状态可以变得更好

  帕累托最优：一个状态不存在帕累托改善。

- 纳什均衡：如果其他参与者保持不变，任何一个参与者都无法通过单方面改变自己的策略来获得更优状态，则这个状态称为纳什均衡点。（占优策略均衡一定是纳什均衡）

  在有限博弈中，若允许所有人混合策略，则一定存在纳什均衡点。

### 如何计算纳什均衡

短视最优响应

极小化极大理论



### 合作博弈

（不考）



---

## Lecture 24. 仿真

对外观、现象、行动的仿真

### 一、外观

#### ---几何表达：

- 显示表达

  1. 点云表示

  2. 体素表示（分辨率问题）

     <img src="./../typora-images\image-20250529155225821.png" alt="image-20250529155225821" style="zoom:15%;" /><img src="./../typora-images\image-20250529155533070.png" alt="image-20250529155533070" style="zoom:25%;" />

  3. 多边形网格（用多边形面片表示，通常为三角或四边形网格，记录顶点的位置，面片上的点用插值计算得到）<img src="./../typora-images\image-20250529155513230.png" alt="image-20250529155513230" style="zoom:25%;" />

- 隐式表达

  有符号距离函数

#### ---几何获取：

#### ---几何绘制：

- 光栅化绘制

- 光线追踪

  1. 正交投影 / 透视投影

  2. 着色（shading）= 物体颜色 + 光照

     - 最简单的光照模型：朗伯模型（理想漫反射，表面均匀粗糙）

       朗伯余弦定律：反射的光强取决于夹角

     - 不断迭代

       

### 二、现象

- 时间离散化

- 空间离散化

  - 欧拉视角：离散化空间（空间不变）
  - 拉格朗日视角：离散化物体上的点

- 数值积分：

  - 显式/前向欧拉积分
  
  - 隐式/后向欧拉积分：需要求解方程，计算量大。

  - 半隐式欧拉积分

    <img src="./../typora-images\image-20250531194528488.png" alt="image-20250531194528488" style="zoom:33%;" />
  
  *数值稳定性：不会趋向于无穷大。
  
  - 无条件稳定：隐式积分（尤其是流体和弹簧）
  - 条件稳定：步长足够小，则半隐式乃至显式都勉强可控
  
  *仿真精度问题：
  
  <img src="./../typora-images\image-20250529165006644.png" alt="image-20250529165006644" style="zoom:25%;" />



### 三、行动

- 蒙皮
- 关键帧动画
- 动捕



### 四、问题

仿真最大问题：虚实鸿沟 (Sim2Real Gap)

感知偏差，例如：

- 仿真系统中的信息可能过多，部分信息在真实场景可能无法获取
- 仿真系统中的信息可能过于“干净”，无法准确模拟真实传感器的感知模式
- 仿真系统中的信息可能不足，缺少真实场景的信息

系统偏差，例如：

- 仿真系统无法准确对某些真实现象进行建模，例如碰撞、摩擦的内在机制
- 仿真系统的运动模型过于简化或不准确，参数含义与真实世界区别较大
- 仿真系统未能预见真实世界中可能出现的场景

应对：

- 系统识别
- 域自适应
- 域随机化
